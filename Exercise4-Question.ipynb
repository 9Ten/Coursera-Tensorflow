{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exercise4-Question.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/lmoroney/dlaicourse/blob/master/Exercises/Exercise%204%20-%20Handling%20Complex%20Images/Exercise%204-Question.ipynb","timestamp":1553742943875}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"UncprnB0ymAE","colab_type":"text"},"cell_type":"markdown","source":["Below is code with a link to a happy or sad dataset which contains 80 images, 40 happy and 40 sad. \n","Create a convolutional neural network that trains to 100% accuracy on these images,  which cancels training upon hitting training accuracy of >.999\n","\n","Hint -- it will work best with 3 convolutional layers."]},{"metadata":{"id":"7Vti6p3PxmpS","colab_type":"code","outputId":"8c14e608-38aa-41f0-d7bb-119c49c3cf73","executionInfo":{"status":"ok","timestamp":1553745383675,"user_tz":-420,"elapsed":3527,"user":{"displayName":"Panapot Poungnak","photoUrl":"https://lh5.googleusercontent.com/-yoZFI7qNoDY/AAAAAAAAAAI/AAAAAAAAAL4/pM5IPYqfcFU/s64/photo.jpg","userId":"04817842887850760597"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"cell_type":"code","source":["import tensorflow as tf\n","import os\n","import zipfile\n","\n","\n","DESIRED_ACCURACY = 0.999\n","\n","!wget --no-check-certificate \\\n","    \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\" \\\n","    -O \"/tmp/happy-or-sad.zip\"\n","\n","zip_ref = zipfile.ZipFile(\"/tmp/happy-or-sad.zip\", 'r')\n","zip_ref.extractall(\"/tmp/h-or-s\")\n","zip_ref.close()\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    # Your Code\n","    def on_epoch_end(self, epoch, logs={}):\n","        if(logs.get('acc')>DESIRED_ACCURACY):\n","            print(\"\\nReached 99.9% accuracy so cancelling traning!\")\n","            self.model.stop_training = True\n","\n","callbacks = myCallback()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2019-03-28 03:56:24--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2670333 (2.5M) [application/zip]\n","Saving to: ‘/tmp/happy-or-sad.zip’\n","\n","\r/tmp/happy-or-sad.z   0%[                    ]       0  --.-KB/s               \r/tmp/happy-or-sad.z 100%[===================>]   2.55M  --.-KB/s    in 0.02s   \n","\n","2019-03-28 03:56:24 (104 MB/s) - ‘/tmp/happy-or-sad.zip’ saved [2670333/2670333]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"6DLGbXXI1j_V","colab_type":"code","outputId":"18fb5f66-efbc-4397-8500-e2fa53d1e788","executionInfo":{"status":"ok","timestamp":1553745385359,"user_tz":-420,"elapsed":1049,"user":{"displayName":"Panapot Poungnak","photoUrl":"https://lh5.googleusercontent.com/-yoZFI7qNoDY/AAAAAAAAAAI/AAAAAAAAAL4/pM5IPYqfcFU/s64/photo.jpg","userId":"04817842887850760597"}},"colab":{"base_uri":"https://localhost:8080/","height":507}},"cell_type":"code","source":["# This Code Block should Define and Compile the Model\n","model = tf.keras.models.Sequential([\n","    # convilotions_layer_1\n","    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPool2D(2, 2),\n","    # convilotions_layer_2\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPool2D(2, 2),\n","    # convilotions_layer_3\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPool2D(2, 2),\n","    \n","    # classifier\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","from tensorflow.keras.optimizers import RMSprop\n","\n","model.summary()\n","model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['acc'])"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 148, 148, 16)      448       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 34, 34, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 17, 17, 32)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 9248)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               4735488   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 513       \n","=================================================================\n","Total params: 4,750,337\n","Trainable params: 4,750,337\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"4Ap9fUJE1vVu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a08bdf50-fef6-4f5e-cfc4-2a3abf9fea1f","executionInfo":{"status":"ok","timestamp":1553745589418,"user_tz":-420,"elapsed":1077,"user":{"displayName":"Panapot Poungnak","photoUrl":"https://lh5.googleusercontent.com/-yoZFI7qNoDY/AAAAAAAAAAI/AAAAAAAAAL4/pM5IPYqfcFU/s64/photo.jpg","userId":"04817842887850760597"}}},"cell_type":"code","source":["# This code block should create an instance of an ImageDataGenerator called train_datagen \n","# And a train_generator by calling train_datagen.flow_from_directory\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale=1/255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    \"/tmp/h-or-s\",\n","    target_size=(150, 150),\n","    class_mode='binary',\n","    batch_size=32\n",")\n","\n","# Expected output: 'Found 80 images belonging to 2 classes'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Found 80 images belonging to 2 classes.\n"],"name":"stdout"}]},{"metadata":{"id":"48dLm13U1-Le","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":457},"outputId":"388e4056-a5b5-4c14-e381-2c3b014fc59c","executionInfo":{"status":"ok","timestamp":1553745743488,"user_tz":-420,"elapsed":9134,"user":{"displayName":"Panapot Poungnak","photoUrl":"https://lh5.googleusercontent.com/-yoZFI7qNoDY/AAAAAAAAAAI/AAAAAAAAAL4/pM5IPYqfcFU/s64/photo.jpg","userId":"04817842887850760597"}}},"cell_type":"code","source":["# This code block should call model.fit_generator and train for\n","# a number of epochs. \n","history = model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=2,\n","    epochs=15,\n","    verbose=1,\n","    callbacks=[callbacks]\n",")\n","    \n","# Expected output: \"Reached 99.9% accuracy so cancelling training!\"\""],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/15\n","3/3 [==============================] - 3s 1s/step - loss: 1.9931 - acc: 0.5250\n","Epoch 2/15\n","3/3 [==============================] - 0s 79ms/step - loss: 0.4971 - acc: 0.9000\n","Epoch 3/15\n","3/3 [==============================] - 0s 100ms/step - loss: 0.4242 - acc: 0.8375\n","Epoch 4/15\n","3/3 [==============================] - 0s 68ms/step - loss: 0.2919 - acc: 0.9375\n","Epoch 5/15\n","3/3 [==============================] - 0s 92ms/step - loss: 0.1812 - acc: 0.9375\n","Epoch 6/15\n","3/3 [==============================] - 0s 68ms/step - loss: 0.1464 - acc: 0.9625\n","Epoch 7/15\n","3/3 [==============================] - 0s 92ms/step - loss: 0.1312 - acc: 0.9625\n","Epoch 8/15\n","3/3 [==============================] - 0s 68ms/step - loss: 0.1880 - acc: 0.9000\n","Epoch 9/15\n","3/3 [==============================] - 0s 100ms/step - loss: 0.0772 - acc: 0.9750\n","Epoch 10/15\n","2/3 [===================>..........] - ETA: 0s - loss: 0.0593 - acc: 1.0000\n","Reached 99.9% accuracy so cancelling traning!\n","3/3 [==============================] - 0s 66ms/step - loss: 0.0508 - acc: 1.0000\n"],"name":"stdout"}]}]}